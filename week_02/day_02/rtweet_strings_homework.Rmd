---
title: "Untitled"
output: html_document
date: "2023-03-28"
---

```{r}
library(tidyverse)
tweets <- read_csv("code_clan_tweets.csv")
dim(tweets) # 234 rows,27 columns
```


```{r}
names(tweets)
```
Question 2: Find the total number of favourites (stored in favorite_count) that CodeClan tweets have got. Don’t add a tweet’s favorite_count to the total when the tweet was quoted (see the is_quote variable).

```{r}
favourites_total <- tweets %>% 
  filter(is_quote == FALSE) 
```


```{r}
favourites_total %>% 
  summarise(favorite_total = sum(favorite_count))
```



Question 3: Summarise the mean number of retweets (retweet_count), split by the type of platform that was used to tweet (source). Again, omit quoted tweets from the mean.

```{r}
tweets %>% 
  distinct(source)
```



```{r}
retweet_count_mean <- tweets %>% 
  filter(is_quote == FALSE) %>% 
  group_by(source) %>% 
  summarise(mean_retweets = mean(retweet_count))
retweet_count_mean
```

Question 4.
Count the total number of likes (i.e. total of favorite_count), split by media type, and arrange them from most likes to least. Assume that any tweets without a listed media type are of type “text”.

step 1: convert NAs in Media to "Text", then group and summarise
```{r}
total_likes <- tweets %>%
  mutate(media_type = coalesce(media_type, "text")) %>%
  group_by(media_type) %>% 
  summarise(total_likes = sum(favorite_count)) %>% 
  arrange(desc(total_likes))
  
total_likes
```

Question 5.
Find the mean number of characters that a CodeClan tweet contains. You can either find a way to count the text in the text variable, or use the variable display_text_width which contains a count. Checking both would be a good idea if possible to see if they match (but it’s not essential).


```{r}
# count the length of string using 'str_length' then check if this is equal to display text width
tweet_length <- tweets %>% 
  mutate(tweet_length = str_length(text), .after = text,
         length_check = (tweet_length == display_text_width))
head(tweet_length)
```



Question 6.
The code_clan_info.csv data file contains status_url along with other info. Load this in, and join it to the code_clan_tweets tibble, so that you have a status_url for each tweet. Decide which variable to join the tibbles on.

```{r}
info <- read_csv("code_clan_info.csv")
```

```{r}
names(info)
```
```{r}
tweet_join_info <- 
  full_join(tweets, info, by = "tweet_id")

names(tweet_join_info)
```
```{r}
dim(tweet_join_info)
```

Question 7.
From your new joined data, create a new tibble codeclan_hashtags containing only tweet_id and hashtags, then convert hashtags into lowercase for analysis. Keep only those tweets with hashtags.


```{r}
codeclan_hashtags <- tweet_join_info %>% 
  select(tweet_id, hashtags) %>% 
  mutate(hashtags = str_to_lower(hashtags)) %>% 
  filter(!is.na(hashtags))
head(codeclan_hashtags)
```

Extension: Question 8
Some tweets have more than one hashtag, denoted by the c( symbols at the start of the string. Use the str_sub() and str_detect() functions and your codeclan_hashtags tibble from above to find all the cases in which the hashtag string begins with charactersc(.

```{r}
first_letters <- codeclan_hashtags %>% 
  mutate(first_letters= str_sub(hashtags, start = 1, end = 2)) %>% 
  filter(str_detect(first_letters, "c\\("))
```

Question 9. Use the str_detect() function to find all tweets with text that mentions “Edinburgh”, and count how many such tweets there are.

```{r}
Edinburgh <- tweets %>% 
  select(text) %>%
  filter(str_detect(text, "Edinburgh")) %>% 
  summarise(count = n())
Edinburgh
```

Question 10.
Use str_extract_all() with a regular expression to find out which Twitter users CodeClan have been tweeting.

```{r}
user_pattern <- "@[a-z0-9]+"
users <- tweets %>% 
  select(text)
str_extract_all(users, user_pattern)
```


Cailean's answer

```{r}
tweets %>% 
  mutate(tweeted_to = str_extract_all(text, pattern = "@+[A-Za-z0-9\\_]+"), .after = text) %>% 
  unnest_wider(tweeted_to, names_sep = "_") %>% 
  select(tweeted_to_1:tweeted_to_6)
```

pattern translate = one or more @ followed by alpha numberic, esca

unnest wider returns one column for each instance, each column called "Tweeted_to" with an "_" to separate between each next column (i.e. "tweeted_to_1", "tweeted_to_2" and so on...)

 %>% 
  str_extract_all(users, user_pattern)


user_pattern <- "@[a-z0-9]+"











